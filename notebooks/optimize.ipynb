{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/commit-t5/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from optimum.onnxruntime import (\n",
    "    ORTModelForSeq2SeqLM,\n",
    ")\n",
    "\n",
    "model_id = \"SEBIS/code_trans_t5_base_commit_generation_transfer_learning_finetune\"\n",
    "\n",
    "# model = ORTModelForSeq2SeqLM.from_pretrained(model_id, export=True)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained(\"ct-base-commits\")\n",
    "model = ORTModelForSeq2SeqLM.from_pretrained(\"ct-base-commits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/commit-t5/venv/lib/python3.10/site-packages/optimum/onnxruntime/configuration.py:735: FutureWarning: disable_embed_layer_norm will be deprecated soon, use disable_embed_layer_norm_fusion instead, disable_embed_layer_norm_fusion is set to True.\n",
      "  warnings.warn(\n",
      "Optimizing model...\n",
      "symbolic shape inference disabled or failed.\n",
      "Configuration saved in ct-base-commits-optimized/ort_config.json\n",
      "Optimized model saved at: ct-base-commits-optimized (external data format: False; saved all tensor to one file: True)\n",
      "Generation config file not found, using a generation config created from the model config.\n",
      "/home/kevin/commit-t5/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from optimum.onnxruntime import  OptimizationConfig, ORTOptimizer, ORTModelForSeq2SeqLM\n",
    "\n",
    "save_dir = \"ct-base-commits-optimized\"\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = ORTOptimizer.from_pretrained(model)\n",
    "\n",
    "# Define the optimization strategy by creating the appropriate configuration\n",
    "optimization_config = OptimizationConfig(\n",
    "    optimization_level=2,\n",
    "    enable_transformers_specific_optimizations=True,\n",
    "    optimize_for_gpu=False,\n",
    ")\n",
    "\n",
    "# Optimize the model\n",
    "optimizer.optimize(save_dir=save_dir, optimization_config=optimization_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "optimized_model = ORTModelForSeq2SeqLM.from_pretrained(save_dir)\n",
    "tokens = tokenizer(\"This is a sample input\", return_tensors=\"pt\")\n",
    "outputs = optimized_model.generate(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/commit-t5/venv/lib/python3.10/site-packages/optimum/onnxruntime/configuration.py:735: FutureWarning: disable_embed_layer_norm will be deprecated soon, use disable_embed_layer_norm_fusion instead, disable_embed_layer_norm_fusion is set to True.\n",
      "  warnings.warn(\n",
      "Optimizing model...\n",
      "symbolic shape inference disabled or failed.\n",
      "Configuration saved in ct-base-commits-onnx/ort_config.json\n",
      "Optimized model saved at: ct-base-commits-onnx (external data format: False; saved all tensor to one file: True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('ct-base-commits-onnx')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from optimum.onnxruntime import (\n",
    "    AutoOptimizationConfig, ORTOptimizer\n",
    ")\n",
    "\n",
    "save_dir = \"ct-base-commits-onnx\"\n",
    "\n",
    "optimizer = ORTOptimizer.from_pretrained(model)\n",
    "optimization_config = AutoOptimizationConfig.O3()\n",
    "\n",
    "# Optimize the model\n",
    "optimizer.optimize(save_dir=save_dir, optimization_config=optimization_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation config file not found, using a generation config created from the model config.\n"
     ]
    }
   ],
   "source": [
    "model_onnx = ORTModelForSeq2SeqLM.from_pretrained(\"ct-base-commits-onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimum.pipelines import pipeline\n",
    "onnx_seq2seq = pipeline(\"text2text-generation\", model=model_onnx, accelerator=\"ort\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.73 s, sys: 4.46 ms, total: 8.74 s\n",
      "Wall time: 691 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Add a download of React in README . md'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "input_text = \"\"\"\n",
    "diff --git a/README.md b/README.md\n",
    "index 9b077d6..c9ee84c 100644\n",
    "--- a/README.md\n",
    "+++ b/README.md\n",
    "@@ -6,7 +6,7 @@ React is a JavaScript library for building user interfaces.\n",
    " * **Efficient:** React minimizes interactions with the DOM by using a mock representation of the DOM.\n",
    " * **Flexible:** React works with the libraries and frameworks that you already know.\n",
    " \n",
    "-[Learn how to use React in your own project.](http://facebook.github.io/docs/getting-started.html)\n",
    "+[Learn how to use React in your own project.](http://facebook.github.io/react/docs/getting-started.html)\n",
    " \n",
    " ## Examples\n",
    " \n",
    "@@ -41,7 +41,7 @@ The fastest way to get started is to serve JavaScript from the CDN:\n",
    " <script src=\"http://fb.me/JSXTransformer-0.3.0.js\"></script>\n",
    " ```\n",
    " \n",
    "-We've also built a [starter kit](#) which might be useful if this is your first time using React. It includes a webpage with an example of using React with live code.\n",
    "+We've also built a [starter kit](http://facebook.github.io/react/downloads/react-0.3.0.zip) which might be useful if this is your first time using React. It includes a webpage with an example of using React with live code.\n",
    " \n",
    " If you'd like to use [bower](http://bower.io), it's as easy as:\n",
    "\"\"\"\n",
    "onnx_seq2seq(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fd25b8444efc7bd375a5f52d7295fc56d12a7b735c42b4d370db3bc31589091"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
